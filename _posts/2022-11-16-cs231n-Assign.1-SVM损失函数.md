---
layout: post
title: cs231n Assign.1 SVM损失函数
categories: 学习记录cs231n AI 数学
tags: SVM_loss AI Code_by_Math
---
# cs231n Assign.1 SVM损失函数

在求损失函数梯度的时候，感觉无从下手，这需要通过梯度的本质来解决。损失函数的梯度也就是对SVM loss 求梯度：

$$
\begin{aligned}
L_{i} &=\sum_{j \neq y_{i}}\left\{\begin{array}{ll}
0 & \text { if } s_{y_{i}} \geq s_{j}+1 \\
s_{j}-s_{y_{i}}+1 & \text { otherwise }
\end{array}\right.\\
&=\sum_{j \neq y_{i}} \max \left(0, s_{j}-s_{y_{i}}+1\right)
\end{aligned}
$$
要求取某个权重单元$w_{ij}$对损失的梯度，也就是$\frac{\partial{L_i}}{\partial{w_{ij}}}$,不妨只考虑有以$ s_{y_{i}} \geq s_{j}+1 $下的计算方法：

$$
\begin{aligned}\frac{\part{L_i}}{\part{w_{ij}}}=\frac{\part{s_j}}{\part{w_{ij}}}\end{aligned}
$$
注意到$s_i=f(W,x)$，此处函数的权重为$W_{D\times C}$，可以写作向量的形式：
$$
W_{D\times C} = [v_1 ,v_2 ,\cdots,v_c ]，v_c = [w_{1c},w_{2c},\cdots , w_{dc}]
$$
其中$v$代表一个n维向量，那么可以将上式改写为:
$$
\begin{aligned}s_j &= \sum_D w_{ij} x_i\\ \frac{\partial{L_i}}{\partial{w_{ij}}}&=\frac{\partial{s_j}}{\partial{w_{ij}}}-\frac{\partial{s_{y_i}}}{\partial{w_{ij}}}\\&=\begin{cases}X_i &,j=j\\ -X_i &, j = y_i \\0 &,else\end{cases}\end{aligned}
$$
这里最后的结果应该分类讨论来看，由于求导所得的结果是对于所有$w_{ij}$而言的，也就是说，所得是一个$D\times C$的矩阵，求导的结果便是某些列被置为$X$,而一部分保留为0.

从直观上看，$dW$ 的每一列都是由相同的$s_j$求导而来，条件$ s_{y_{i}} \geq s_{j}+1 $满足的话那么这一列的导数就是向量$X_D$，如果不满足那么其导数为0。借鉴最优化中的相关技巧，不妨设满足条件的下标$j$集合为$D$，整体导数可以记为：
$$
\begin{aligned}dW&=\frac{\part L}{\part W} \\&= [X,X,0,X,0,\cdots]\\(dW_{\cdot j}&=\begin{cases}0 ,j \notin D\\X ,j \in D\end{cases})\end{aligned}
$$
在编程实现时，计算导数直接在计算loss时候添加就可以，避免二次判断，具体实现可以参考我github上的提交记录。

此外，还需要注意的一点是正则化项同样是需要添加至损失函数的梯度计算中。