---
layout: post
title: 基于深度学习的X光侧面头影标志点检测研究_敖悦源 论文阅读笔记
categories: 论文阅读 CV 学习记录
tags: Transformer 医学图像识别
---
# 基于深度学习的X光侧面头影标志点检测研究_敖悦源 论文阅读笔记

这一论文解决的问题是X 光侧面头影标志点的定位，主要有以下贡献：

1. 提出了一种端到端的深度网络模型`FARnet`，自动监测标志点的信息。
2. 使用预训练的网络架构作为骨干网络，缓解数据有限的问题。
3. 构建了新的损失函数来进行精确的热图回归，关注靠近标志点周围的像素点，且在同时抑制远离像素点的损失。
4. 为了解决长语义问题，提出一种基于Transformer的算法模型`TSLDNet`。把关键点检测问题转化为两阶段处理。首先利用RoI来估计中心点位置，随后用基于Transformer的标志点检测网络精确定位。
5. 为了同时利用 CNN 和 Transformer 的优势，提出了一种基于 Swin Transformer 的算法模型 Swin-CE，该模型结合了 Swin Transformer 编码器和 CNN 编码器。CNN 编码器可以有效地提取局部特征，而 Swin Transformer 编码器擅长捕获全局特征和进行远程语义信息交互。同时，该模型还利用跳跃连接来整合由两个编码器产生的特征，最后利用解码器进行最终的热图回归。

下面进行详细阅读

## 绪论

讲述了头影测量的必要性。以及该领域前人的一些进展，主要使用了什么方法以解决该关键点检测问题。介绍的算法包括了LeNet（最先提出神经网络架构），AlexNet随后在比赛中获得较好成绩，创新之处在于引入了池化层和dropout来减小过拟合风险。VGGNet在网络深度层面对前人的成果进行改进，并且引入了1 × 1 的卷积核，这一卷积核的引入改变了卷积核通道的维度，而不是在卷积的空间中做处理。

在之后GoogLeNet/Inception,使用多层卷积来代替更大的一个卷积核，但是最后的参数数量减少了。还使用全局平均层来代替最后的全连接层，详细的在[这篇](https://zhuanlan.zhihu.com/p/50754671)。之后提出了残差模块[^1]，来解决模型退化、梯度消失等问题。随后提出的DenseNet中增加了层与层之间的链接数目，更加有效的减弱了梯度消失问题。

介绍了Transformer，However, unlike RNNs, transformers process the entire input all at once. The attention mechanism provides context for any position in the input sequence. This allows for more [parallelization](https://en.wikipedia.org/wiki/Parallel_computing) than RNNs and therefore reduces training times. 

Transformer is one of the seq2seq models .That abstract vector is fed into the Decoder which turns it into an output sequence. The output sequence can be in another language, symbols, a copy of the input.



[^1]: https://en.wikipedia.org/wiki/Residual_neural_network